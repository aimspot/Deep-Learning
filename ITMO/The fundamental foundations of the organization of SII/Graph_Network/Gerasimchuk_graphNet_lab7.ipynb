{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5107992-8152-4a53-99a2-7ef9097f004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 02:10:51.675266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from pymatgen.core import Structure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257b1f55-c871-4d31-82fd-67338983715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.19.2\n"
     ]
    }
   ],
   "source": [
    "print ('Numpy version:', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5316a740-1edb-4f26-84b1-d017acb2099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pymatgen_dict(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        d = json.load(f)\n",
    "    return Structure.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7d7001-b494-421f-952d-cbfaaac387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_within_threshold(prediction, target):\n",
    "   # вычислите абсолютную погрешность по энергии для каждой системы.\n",
    "    # затем подсчитайте количество систем, в которых максимальная ошибка энергопотребления составляет < 0,02.\n",
    "    e_thresh = 0.02\n",
    "    error_energy = tf.math.abs(target - prediction)\n",
    "\n",
    "    success = tf.math.count_nonzero(error_energy < e_thresh)\n",
    "    total = tf.size(target)\n",
    "    return success / tf.cast(total, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1798965c-40c3-4477-bc20-38e232c97547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path):\n",
    "    dataset_path = Path(dataset_path)\n",
    "    targets = pd.read_csv(dataset_path / \"targets.csv\", index_col=0)\n",
    "    struct = {\n",
    "        item.name.strip(\".json\"): read_pymatgen_dict(item)\n",
    "        for item in (dataset_path / \"structures\").iterdir()\n",
    "    }\n",
    "\n",
    "    data = pd.DataFrame(columns=[\"structures\"], index=struct.keys())\n",
    "    data = data.assign(structures=struct.values(), targets=targets)\n",
    "\n",
    "    return train_test_split(data, test_size=0.25, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674a0bbb-918e-468d-a8e7-ddd6535e0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(cutoff, lr):\n",
    "    nfeat_bond = 10\n",
    "    r_cutoff = cutoff\n",
    "    gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "    gaussian_width = 0.8\n",
    "    \n",
    "    return MEGNetModel(\n",
    "        graph_converter=CrystalGraph(cutoff=r_cutoff),\n",
    "        centers=gaussian_centers,\n",
    "        width=gaussian_width,\n",
    "        loss=[\"MAE\"],\n",
    "        npass=2,\n",
    "        lr=lr,\n",
    "        metrics=energy_within_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23406073-85b6-4a4e-9d88-ca87bef208e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/user/a/aimspot/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    " train, test = prepare_dataset('data/dichalcogenides_public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efbfb659-83f4-4608-8b45-f49112c6f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "cutoff = 4\n",
    "#with tf.device(\"/gpu:3\"):\n",
    "model = prepare_model(\n",
    "    float(cutoff),\n",
    "    float(lr), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "380c6ca6-f638-4fc7-b829-96ad1e21e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6c117b-df4d-4a44-abbf-b75b563c12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 35s 1s/step - loss: 0.8289 - energy_within_threshold: 0.0000e+00\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2afc210b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2afc210b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.7310 - energy_within_threshold: 3.4244e-04\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.6060 - energy_within_threshold: 0.0132\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.4564 - energy_within_threshold: 0.0747\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4546 - energy_within_threshold: 0.0000e+00\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4648 - energy_within_threshold: 0.0026\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.4611 - energy_within_threshold: 0.0043\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4640 - energy_within_threshold: 0.0017\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4575 - energy_within_threshold: 6.6024e-04\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4565 - energy_within_threshold: 0.0055\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4495 - energy_within_threshold: 0.0046\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.4602 - energy_within_threshold: 0.0069\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4531 - energy_within_threshold: 0.0031\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4600 - energy_within_threshold: 0.0029\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4564 - energy_within_threshold: 0.0019\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.4650 - energy_within_threshold: 4.5258e-04\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4586 - energy_within_threshold: 0.0000e+00\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4609 - energy_within_threshold: 6.9874e-05\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4553 - energy_within_threshold: 0.0016\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4618 - energy_within_threshold: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:3\"):\n",
    "    model.train(\n",
    "        train.structures,\n",
    "        train.targets,\n",
    "        validation_structures=test.structures,\n",
    "        validation_targets=test.targets,\n",
    "        epochs=int(epochs),\n",
    "        batch_size=int(batch_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6ac4431-7106-470b-89f3-2137a33eb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model(\n",
    "    float(cutoff),\n",
    "    float(lr), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1b5ae82-bf92-4f68-9adc-252bfe4ed3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('callback/val_mae_00007_0.459013.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2efa43f5-9014-4e18-b1db-a3618cb7896b",
   "metadata": {},
   "outputs": [],
   "source": [
    " dataset_path = Path('data/dichalcogenides_private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0254d5c7-6d8e-45b3-90a7-066a98795418",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = {item.name.strip('.json'): read_pymatgen_dict(item) for item in (dataset_path/'structures').iterdir()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "019cfeff-9771-4779-a161-8d3b8b528c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test = pd.DataFrame(columns=['id', 'structures'], index=struct.keys())\n",
    "private_test = private_test.assign(structures=struct.values())\n",
    "private_test = private_test.assign(predictions=model.predict_structures(private_test.structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f842a1a6-18f5-4ea1-ac31-807fa0ea0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test[['predictions']].to_csv('./submission.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50add5-c60e-4311-b46f-d300adcc2ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
